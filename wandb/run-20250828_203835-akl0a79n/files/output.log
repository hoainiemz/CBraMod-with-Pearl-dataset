100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:46<00:00,  1.53it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00,  7.97it/s]
Epoch 1 : Training Loss: 1.61326, acc: 0.21600, kappa: 0.02000, f1: 0.14604, LR: 0.00001, Time elapsed 0.80 mins
[[  0   5  29 111   5]
 [  2   8  29 106   5]
 [  1   5  34 104   6]
 [  0   3  31 112   4]
 [  0   4  29 109   8]]
kappa increasing....saving weights !!
Val Evaluation: acc: 0.21600, kappa: 0.02000, f1: 0.14604
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.39it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.47it/s]
Epoch 2 : Training Loss: 1.59644, acc: 0.22000, kappa: 0.02500, f1: 0.16841, LR: 0.00001, Time elapsed 0.20 mins
[[  5  12  27 102   4]
 [  5   9  32  91  13]
 [  2   8  32  99   9]
 [  1   6  30 104   9]
 [  0   7  24 104  15]]
kappa increasing....saving weights !!
Val Evaluation: acc: 0.22000, kappa: 0.02500, f1: 0.16841
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.39it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.74it/s]
Epoch 3 : Training Loss: 1.58359, acc: 0.25333, kappa: 0.06667, f1: 0.23948, LR: 0.00001, Time elapsed 0.20 mins
[[15 34 18 39 44]
 [10 44 14 28 54]
 [ 9 23 24 36 58]
 [12 32 16 40 50]
 [ 8 21 11 43 67]]
kappa increasing....saving weights !!
Val Evaluation: acc: 0.25333, kappa: 0.06667, f1: 0.23948
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.40it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.86it/s]
Epoch 4 : Training Loss: 1.56747, acc: 0.25600, kappa: 0.07000, f1: 0.24608, LR: 0.00001, Time elapsed 0.20 mins
[[31 16 22 58 23]
 [28 26 12 51 33]
 [18  9 20 56 47]
 [24 11 19 65 31]
 [19  8 12 61 50]]
kappa increasing....saving weights !!
Val Evaluation: acc: 0.25600, kappa: 0.07000, f1: 0.24608
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.38it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.87it/s]
Epoch 5 : Training Loss: 1.55137, acc: 0.24533, kappa: 0.05667, f1: 0.23412, LR: 0.00001, Time elapsed 0.20 mins
[[29 16 17 53 35]
 [28 19 19 46 38]
 [16  9 24 50 51]
 [17 15 18 56 44]
 [19 15 15 45 56]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.49it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.66it/s]
Epoch 6 : Training Loss: 1.52755, acc: 0.22400, kappa: 0.03000, f1: 0.19552, LR: 0.00001, Time elapsed 0.19 mins
[[18 13  9 59 51]
 [30 17  3 50 50]
 [22  9  8 47 64]
 [20  9 10 55 56]
 [20  7  7 46 70]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.50it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.22it/s]
Epoch 7 : Training Loss: 1.50405, acc: 0.23467, kappa: 0.04333, f1: 0.21715, LR: 0.00001, Time elapsed 0.19 mins
[[36 14  8 39 53]
 [42 24  9 32 43]
 [29 12 10 32 67]
 [30 17 12 38 53]
 [23 16  5 38 68]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.52it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.32it/s]
Epoch 8 : Training Loss: 1.47339, acc: 0.23867, kappa: 0.04833, f1: 0.23365, LR: 0.00001, Time elapsed 0.19 mins
[[50 19 15 37 29]
 [52 23 18 29 28]
 [43 11 25 32 39]
 [38 19 18 37 38]
 [41 18 15 32 44]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.47it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 19.82it/s]
Epoch 9 : Training Loss: 1.44557, acc: 0.23600, kappa: 0.04500, f1: 0.23514, LR: 0.00001, Time elapsed 0.19 mins
[[29 26 27 31 37]
 [31 34 25 29 31]
 [21 19 39 28 43]
 [26 27 33 29 35]
 [27 20 20 37 46]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.33it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.05it/s]
Epoch 10 : Training Loss: 1.41793, acc: 0.25467, kappa: 0.06833, f1: 0.24731, LR: 0.00001, Time elapsed 0.20 mins
[[33 19 16 26 56]
 [32 29 19 19 51]
 [23 18 32 22 55]
 [22 23 25 29 51]
 [20 16 18 28 68]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.33it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.19it/s]
Epoch 11 : Training Loss: 1.37297, acc: 0.24533, kappa: 0.05667, f1: 0.24234, LR: 0.00001, Time elapsed 0.20 mins
[[47 25 18 24 36]
 [43 35 18 19 35]
 [38 21 25 21 45]
 [36 30 20 32 32]
 [35 24 17 29 45]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.32it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 20.63it/s]
Epoch 12 : Training Loss: 1.35301, acc: 0.22400, kappa: 0.03000, f1: 0.21782, LR: 0.00001, Time elapsed 0.20 mins
[[45 19 15 29 42]
 [50 22 19 24 35]
 [43 13 22 30 42]
 [40 22 22 30 36]
 [38 16 14 33 49]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.43it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.42it/s]
Epoch 13 : Training Loss: 1.32542, acc: 0.23333, kappa: 0.04167, f1: 0.22636, LR: 0.00001, Time elapsed 0.19 mins
[[41 16 12 39 42]
 [45 20 12 35 38]
 [37 16 22 35 40]
 [32 22 18 41 37]
 [33 15 10 41 51]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.46it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.26it/s]
Epoch 14 : Training Loss: 1.28982, acc: 0.22667, kappa: 0.03333, f1: 0.22066, LR: 0.00001, Time elapsed 0.19 mins
[[34 22 18 28 48]
 [43 25 22 22 38]
 [29 17 33 22 49]
 [27 22 32 21 48]
 [32 16 20 25 57]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:10<00:00,  6.46it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.33it/s]
Epoch 15 : Training Loss: 1.26449, acc: 0.22800, kappa: 0.03500, f1: 0.22478, LR: 0.00001, Time elapsed 0.19 mins
[[32 22 24 27 45]
 [42 26 17 25 40]
 [31 16 31 23 49]
 [27 27 27 30 39]
 [30 17 24 27 52]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.45it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.33it/s]
Epoch 16 : Training Loss: 1.24726, acc: 0.22400, kappa: 0.03000, f1: 0.22008, LR: 0.00001, Time elapsed 0.19 mins
[[42 24 16 26 42]
 [53 30 10 18 39]
 [44 21 22 21 42]
 [35 27 22 27 39]
 [41 21 18 23 47]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.43it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.35it/s]
Epoch 17 : Training Loss: 1.21224, acc: 0.22533, kappa: 0.03167, f1: 0.22323, LR: 0.00001, Time elapsed 0.19 mins
[[38 25 18 32 37]
 [46 30 15 24 35]
 [40 22 24 24 40]
 [35 28 22 32 33]
 [38 20 19 28 45]]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:11<00:00,  6.42it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 21.07it/s]
Epoch 18 : Training Loss: 1.17616, acc: 0.22133, kappa: 0.02667, f1: 0.21116, LR: 0.00001, Time elapsed 0.19 mins
[[26 20 24 26 54]
 [40 21 12 24 53]
 [33 13 28 23 53]
 [33 19 25 24 49]
 [29 13 16 25 67]]
 10%|████████████▏                                                                                                               | 7/71 [00:01<00:10,  6.15it/s]
[33m[W 2025-08-28 20:42:44,457][0m Trial 0 failed with parameters: {'lr': 1.0253509690168497e-05, 'weight_decay': 0.029334453957883984, '--dropout': 0.146398788362281, '--clip_value': 1.397987726295555} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/hyper_optuna.py", line 21, in objective
    score = eval(config, trial)['kappa']
            ~~~~^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/optuna_trainable.py", line 118, in eval
    return t.train_for_multiclass(trial)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py", line 99, in train_for_multiclass
    pred = self.model(x)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_speech.py", line 55, in forward
    feats = self.backbone(x)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/cbramod.py", line 29, in forward
    feats = self.encoder(patch_emb)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 29, in forward
    output = mod(output, src_mask=mask)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 90, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)
            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 107, in _sa_block
    xt = self.self_attn_t(xt, xt, xt,
         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
                          attn_mask=attn_mask,
                          ^^^^^^^^^^^^^^^^^^^^
                          key_padding_mask=key_padding_mask,
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          need_weights=False)[0]
                          ^^^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 1373, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        query,
        ^^^^^^
    ...<17 lines>...
        is_causal=is_causal,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/functional.py", line 6410, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
        q, k, v, attn_mask, dropout_p, is_causal
    )
KeyboardInterrupt
[33m[W 2025-08-28 20:42:44,464][0m Trial 0 failed with value None.[0m
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/hyper_optuna.py", line 34, in <module>
    study.optimize(objective, n_trials=100)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/study.py", line 490, in optimize
    _optimize(
    ~~~~~~~~~^
        study=self,
        ^^^^^^^^^^^
    ...<7 lines>...
        show_progress_bar=show_progress_bar,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
    ~~~~~~~~~~~~~~~~~~~~^
        study,
        ^^^^^^
    ...<8 lines>...
        progress_bar=progress_bar,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial_id = _run_trial(study, func, catch)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py", line 258, in _run_trial
    raise func_err
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py", line 201, in _run_trial
    value_or_values = func(trial)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/hyper_optuna.py", line 21, in objective
    score = eval(config, trial)['kappa']
            ~~~~^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/optuna_trainable.py", line 118, in eval
    return t.train_for_multiclass(trial)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py", line 99, in train_for_multiclass
    pred = self.model(x)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_speech.py", line 55, in forward
    feats = self.backbone(x)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/cbramod.py", line 29, in forward
    feats = self.encoder(patch_emb)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 29, in forward
    output = mod(output, src_mask=mask)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 90, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)
            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 107, in _sa_block
    xt = self.self_attn_t(xt, xt, xt,
         ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
                          attn_mask=attn_mask,
                          ^^^^^^^^^^^^^^^^^^^^
                          key_padding_mask=key_padding_mask,
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                          need_weights=False)[0]
                          ^^^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/activation.py", line 1373, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        query,
        ^^^^^^
    ...<17 lines>...
        is_causal=is_causal,
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/functional.py", line 6410, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
        q, k, v, attn_mask, dropout_p, is_causal
    )
KeyboardInterrupt
Traceback (most recent call last):
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/hyper_optuna.py"[0m, line [35m34[0m, in [35m<module>[0m
    [31mstudy.optimize[0m[1;31m(objective, n_trials=100)[0m
    [31m~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/study.py"[0m, line [35m490[0m, in [35moptimize[0m
    [31m_optimize[0m[1;31m([0m
    [31m~~~~~~~~~[0m[1;31m^[0m
        [1;31mstudy=self,[0m
        [1;31m^^^^^^^^^^^[0m
    ...<7 lines>...
        [1;31mshow_progress_bar=show_progress_bar,[0m
        [1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
    [1;31m)[0m
    [1;31m^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py"[0m, line [35m63[0m, in [35m_optimize[0m
    [31m_optimize_sequential[0m[1;31m([0m
    [31m~~~~~~~~~~~~~~~~~~~~[0m[1;31m^[0m
        [1;31mstudy,[0m
        [1;31m^^^^^^[0m
    ...<8 lines>...
        [1;31mprogress_bar=progress_bar,[0m
        [1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
    [1;31m)[0m
    [1;31m^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py"[0m, line [35m160[0m, in [35m_optimize_sequential[0m
    frozen_trial_id = _run_trial(study, func, catch)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py"[0m, line [35m258[0m, in [35m_run_trial[0m
    raise func_err
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/optuna/study/_optimize.py"[0m, line [35m201[0m, in [35m_run_trial[0m
    value_or_values = func(trial)
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/hyper_optuna.py"[0m, line [35m21[0m, in [35mobjective[0m
    score = [31meval[0m[1;31m(config, trial)[0m['kappa']
            [31m~~~~[0m[1;31m^^^^^^^^^^^^^^^[0m
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/optuna_trainable.py"[0m, line [35m118[0m, in [35meval[0m
    return [31mt.train_for_multiclass[0m[1;31m(trial)[0m
           [31m~~~~~~~~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^[0m
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py"[0m, line [35m99[0m, in [35mtrain_for_multiclass[0m
    pred = self.model(x)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1751[0m, in [35m_wrapped_call_impl[0m
    return [31mself._call_impl[0m[1;31m(*args, **kwargs)[0m
           [31m~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1762[0m, in [35m_call_impl[0m
    return forward_call(*args, **kwargs)
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_speech.py"[0m, line [35m55[0m, in [35mforward[0m
    feats = self.backbone(x)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1751[0m, in [35m_wrapped_call_impl[0m
    return [31mself._call_impl[0m[1;31m(*args, **kwargs)[0m
           [31m~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1762[0m, in [35m_call_impl[0m
    return forward_call(*args, **kwargs)
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/cbramod.py"[0m, line [35m29[0m, in [35mforward[0m
    feats = self.encoder(patch_emb)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1751[0m, in [35m_wrapped_call_impl[0m
    return [31mself._call_impl[0m[1;31m(*args, **kwargs)[0m
           [31m~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1762[0m, in [35m_call_impl[0m
    return forward_call(*args, **kwargs)
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py"[0m, line [35m29[0m, in [35mforward[0m
    output = mod(output, src_mask=mask)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1751[0m, in [35m_wrapped_call_impl[0m
    return [31mself._call_impl[0m[1;31m(*args, **kwargs)[0m
           [31m~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1762[0m, in [35m_call_impl[0m
    return forward_call(*args, **kwargs)
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py"[0m, line [35m90[0m, in [35mforward[0m
    x = x + [31mself._sa_block[0m[1;31m(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)[0m
            [31m~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
  File [35m"/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py"[0m, line [35m107[0m, in [35m_sa_block[0m
    xt = [31mself.self_attn_t[0m[1;31m(xt, xt, xt,[0m
         [31m~~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^[0m
                          [1;31mattn_mask=attn_mask,[0m
                          [1;31m^^^^^^^^^^^^^^^^^^^^[0m
                          [1;31mkey_padding_mask=key_padding_mask,[0m
                          [1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m
                          [1;31mneed_weights=False)[0m[0]
                          [1;31m^^^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1751[0m, in [35m_wrapped_call_impl[0m
    return [31mself._call_impl[0m[1;31m(*args, **kwargs)[0m
           [31m~~~~~~~~~~~~~~~[0m[1;31m^^^^^^^^^^^^^^^^^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py"[0m, line [35m1762[0m, in [35m_call_impl[0m
    return forward_call(*args, **kwargs)
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/modules/activation.py"[0m, line [35m1373[0m, in [35mforward[0m
    attn_output, attn_output_weights = [31mF.multi_head_attention_forward[0m[1;31m([0m
                                       [31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~[0m[1;31m^[0m
        [1;31mquery,[0m
        [1;31m^^^^^^[0m
    ...<17 lines>...
        [1;31mis_causal=is_causal,[0m
        [1;31m^^^^^^^^^^^^^^^^^^^^[0m
    [1;31m)[0m
    [1;31m^[0m
  File [35m"/home/aiotlab/miniconda3/lib/python3.13/site-packages/torch/nn/functional.py"[0m, line [35m6410[0m, in [35mmulti_head_attention_forward[0m
    attn_output = scaled_dot_product_attention(
        q, k, v, attn_mask, dropout_p, is_causal
    )
[1;35mKeyboardInterrupt[0m
Exception ignored in atexit callback <function _start_and_connect_service.<locals>.teardown_atexit at 0x73c062cbde40>:
Traceback (most recent call last):
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/wandb/sdk/lib/service_connection.py", line 226, in teardown
    self._router.join()
  File "/home/aiotlab/miniconda3/lib/python3.13/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/home/aiotlab/miniconda3/lib/python3.13/threading.py", line 1092, in join
    self._handle.join(timeout)
KeyboardInterrupt:
