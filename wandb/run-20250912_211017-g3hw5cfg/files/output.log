Namespace(seed=3407, cuda=0, epochs=50, batch_size=64, lr=0.0003, weight_decay=0.05, optimizer='AdamW', clip_value=1, dropout=0.1, classifier='all_patch_reps', downstream_dataset='PEARL', datasets_dir='/mnt/disk1/aiotlab/namth/EEGFoundationModel/datasets/pearl', num_of_classes=2, model_dir='./data/wjq/models_weights/Big/BigFaced', num_workers=16, label_smoothing=0.1, multi_lr=False, frozen=False, use_pretrained_weights=True, foundation_dir='pretrained_weights/pretrained_weights.pth')
The downstream dataset is PEARL
3255 476 874
4605
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=100, bias=True)
  )
  (classifier): Sequential(
    (0): Rearrange('b c s d -> b (c s d)')
    (1): Linear(in_features=19000, out_features=1000, bias=True)
    (2): ELU(alpha=1.0)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=200, bias=True)
    (5): ELU(alpha=1.0)
    (6): Dropout(p=0.1, inplace=False)
  )
  (final_classifier): Sequential(
    (0): Linear(in_features=300, out_features=200, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=200, out_features=1, bias=True)
    (4): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:06<00:00,  8.21it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.73it/s]
Epoch 1 : Training Loss: 0.45579, acc: 0.51050, pr_auc: 0.55936, roc_auc: 0.65665, LR: 0.00030, Time elapsed 0.11 mins
[[123 115]
 [118 120]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 43.14it/s]
Val Evaluation: acc: 0.57755, pr_auc: 0.76809, roc_auc: 0.70983
[[204 264]
 [114 292]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.51050, pr_auc: 0.55936, roc_auc: 0.65665
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.09it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 45.42it/s]
Epoch 2 : Training Loss: 0.13854, acc: 0.59664, pr_auc: 0.63590, roc_auc: 0.70394, LR: 0.00030, Time elapsed 0.08 mins
[[160  78]
 [114 124]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 45.39it/s]
Val Evaluation: acc: 0.55877, pr_auc: 0.75187, roc_auc: 0.71672
[[221 247]
 [144 262]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.59664, pr_auc: 0.63590, roc_auc: 0.70394
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.02it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 46.55it/s]
Epoch 3 : Training Loss: 0.04208, acc: 0.62815, pr_auc: 0.70987, roc_auc: 0.75485, LR: 0.00030, Time elapsed 0.08 mins
[[180  58]
 [119 119]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 45.35it/s]
Val Evaluation: acc: 0.54787, pr_auc: 0.73300, roc_auc: 0.70321
[[235 233]
 [165 241]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.62815, pr_auc: 0.70987, roc_auc: 0.75485
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.05it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 46.55it/s]
Epoch 4 : Training Loss: 0.02773, acc: 0.67017, pr_auc: 0.77447, roc_auc: 0.79449, LR: 0.00030, Time elapsed 0.08 mins
[[198  40]
 [117 121]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 44.80it/s]
Val Evaluation: acc: 0.53530, pr_auc: 0.68206, roc_auc: 0.63838
[[229 239]
 [170 236]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.67017, pr_auc: 0.77447, roc_auc: 0.79449
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.05it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 45.67it/s]
Epoch 5 : Training Loss: 0.00737, acc: 0.65126, pr_auc: 0.73164, roc_auc: 0.76824, LR: 0.00029, Time elapsed 0.08 mins
[[190  48]
 [118 120]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 45.18it/s]
Val Evaluation: acc: 0.52280, pr_auc: 0.70023, roc_auc: 0.64164
[[215 253]
 [168 238]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 10.90it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 45.37it/s]
Epoch 6 : Training Loss: 0.00931, acc: 0.67437, pr_auc: 0.76153, roc_auc: 0.77878, LR: 0.00029, Time elapsed 0.08 mins
[[210  28]
 [127 111]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 43.76it/s]
Val Evaluation: acc: 0.52972, pr_auc: 0.71294, roc_auc: 0.67863
[[233 235]
 [178 228]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 10.87it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 44.97it/s]
Epoch 7 : Training Loss: 0.00578, acc: 0.68067, pr_auc: 0.72567, roc_auc: 0.75936, LR: 0.00029, Time elapsed 0.08 mins
[[204  34]
 [118 120]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 44.40it/s]
Val Evaluation: acc: 0.51880, pr_auc: 0.67920, roc_auc: 0.65740
[[232 236]
 [186 220]]
 73%|████████████████████████████████████████████████████████████████████████████▉                             | 37/51 [00:03<00:01, 10.60it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 170, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 156, in main
    t.train_for_binaryclass()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py", line 179, in train_for_binaryclass
    loss.backward()
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
