_wandb:
    value:
        cli_version: 0.21.4
        e:
            px7eqvpsdzwlw7sxj5czy0v83sanpw2m:
                args:
                    - --epochs
                    - "20"
                    - --batch_size
                    - "16"
                    - --lr
                    - "5e-4"
                    - --downstream_dataset
                    - PEARL
                    - --datasets_dir
                    - mnt/disk1/aiotlab/namth/EEGFoundationModel/datasets/pearl_30s
                    - --num_of_classes
                    - "2"
                    - --modality_mode
                    - mono
                    - --project_name
                    - EEG_HUST_MULTIMODALITY3
                    - --classifier
                    - all_patch_reps_twolayer
                    - --foundation_dir
                    - /mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/pretrained_weights/pretrained_108.pth
                codePath: finetune_kfold_pearl.py
                codePathLocal: finetune_kfold_pearl.py
                email: nam.th180805@gmail.com
                executable: /mnt/disk1/aiotlab/envs/cbramod/bin/python
                git:
                    commit: 7b463f69cd560205b5d4d061bc8f3a2b5906eba1
                    remote: https://github.com/wjq-learning/CBraMod.git
                host: gpus-Super-Server
                os: Linux-6.8.0-65-generic-x86_64-with-glibc2.35
                program: /mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py
                python: CPython 3.12.11
                root: /mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod
                startedAt: "2025-09-17T11:52:32.192067Z"
                writerId: px7eqvpsdzwlw7sxj5czy0v83sanpw2m
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
                - 5
                - 51
                - 53
            "2":
                - 1
                - 5
                - 51
                - 53
            "3":
                - 13
                - 16
            "4": 3.12.11
            "5": 0.21.4
            "12": 0.21.4
            "13": linux-x86_64
batch_size:
    value: 16
classifier:
    value: all_patch_reps_twolayer
clip_value:
    value: 1
cuda:
    value: 0
datasets_dir:
    value: mnt/disk1/aiotlab/namth/EEGFoundationModel/datasets/pearl_30s
downstream_dataset:
    value: PEARL
dropout:
    value: 0.1
epochs:
    value: 20
foundation_dir:
    value: /mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/pretrained_weights/pretrained_108.pth
frozen:
    value: false
label_smoothing:
    value: 0.1
lr:
    value: 0.0005
modality_mode:
    value: mono
model_dir:
    value: ./data/wjq/models_weights/Big/BigFaced
multi_lr:
    value: false
num_folds:
    value: -1
num_of_classes:
    value: 2
num_workers:
    value: 16
optimizer:
    value: AdamW
project_name:
    value: EEG_HUST_MULTIMODALITY3
seed:
    value: 3407
use_pretrained_weights:
    value: true
weight_decay:
    value: 0.05
