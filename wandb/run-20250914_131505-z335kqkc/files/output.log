3103 679 823
4605
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=50, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=50, out_features=100, bias=True)
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Rearrange('b c s d -> b (c s d)')
    (1): Linear(in_features=19000, out_features=1000, bias=True)
    (2): ELU(alpha=1.0)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=100, bias=True)
    (5): ELU(alpha=1.0)
    (6): Dropout(p=0.1, inplace=False)
  )
  (final_classifier): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=1, bias=True)
    (4): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:15<00:00,  3.20it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.35it/s]
Epoch 1 : Training Loss: 0.55580, acc: 0.85710, pr_auc: 0.92185, roc_auc: 0.93348, LR: 0.00030, Time elapsed 0.31 mins
[[1518  133]
 [ 298 1154]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:01<00:00,  9.71it/s]
val Evaluation: acc: 0.68900, pr_auc: 0.76727, roc_auc: 0.74971
[[214 124]
 [ 87 254]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.68900, pr_auc: 0.76727, roc_auc: 0.74971
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.25it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.30it/s]
Epoch 2 : Training Loss: 0.31896, acc: 0.93191, pr_auc: 0.97537, roc_auc: 0.97932, LR: 0.00029, Time elapsed 0.25 mins
[[1516  135]
 [  79 1373]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.74it/s]
val Evaluation: acc: 0.70211, pr_auc: 0.77978, roc_auc: 0.77763
[[207 131]
 [ 71 270]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.70211, pr_auc: 0.77978, roc_auc: 0.77763
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:12<00:00,  4.08it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.83it/s]
Epoch 3 : Training Loss: 0.18720, acc: 0.95107, pr_auc: 0.98907, roc_auc: 0.99035, LR: 0.00028, Time elapsed 0.26 mins
[[1602   49]
 [  99 1353]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 15.42it/s]
val Evaluation: acc: 0.65543, pr_auc: 0.75796, roc_auc: 0.73920
[[226 112]
 [122 219]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.34it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.71it/s]
Epoch 4 : Training Loss: 0.15328, acc: 0.97720, pr_auc: 0.99780, roc_auc: 0.99794, LR: 0.00027, Time elapsed 0.24 mins
[[1603   48]
 [  24 1428]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.59it/s]
val Evaluation: acc: 0.64177, pr_auc: 0.63946, roc_auc: 0.70337
[[190 148]
 [ 95 246]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.11it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.23it/s]
Epoch 5 : Training Loss: 0.06759, acc: 0.98618, pr_auc: 0.99933, roc_auc: 0.99940, LR: 0.00026, Time elapsed 0.25 mins
[[1619   32]
 [  12 1440]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 16.63it/s]
val Evaluation: acc: 0.63255, pr_auc: 0.71152, roc_auc: 0.74168
[[158 180]
 [ 69 272]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.25it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.75it/s]
Epoch 6 : Training Loss: 0.05495, acc: 0.98061, pr_auc: 0.99843, roc_auc: 0.99859, LR: 0.00024, Time elapsed 0.25 mins
[[1612   39]
 [  22 1430]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.46it/s]
val Evaluation: acc: 0.62369, pr_auc: 0.66668, roc_auc: 0.72881
[[153 185]
 [ 70 271]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.17it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.45it/s]
Epoch 7 : Training Loss: 0.06204, acc: 0.97121, pr_auc: 0.99705, roc_auc: 0.99742, LR: 0.00022, Time elapsed 0.25 mins
[[1573   78]
 [  15 1437]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 15.91it/s]
val Evaluation: acc: 0.64943, pr_auc: 0.53023, roc_auc: 0.62326
[[103 235]
 [  2 339]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.20it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.86it/s]
Epoch 8 : Training Loss: 0.03597, acc: 0.98953, pr_auc: 0.99961, roc_auc: 0.99966, LR: 0.00020, Time elapsed 0.25 mins
[[1646    5]
 [  26 1426]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.60it/s]
val Evaluation: acc: 0.60788, pr_auc: 0.54959, roc_auc: 0.61421
[[177 161]
 [105 236]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.25it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.89it/s]
Epoch 9 : Training Loss: 0.02282, acc: 0.99806, pr_auc: 0.99991, roc_auc: 0.99992, LR: 0.00017, Time elapsed 0.24 mins
[[1648    3]
 [   3 1449]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.94it/s]
val Evaluation: acc: 0.82120, pr_auc: 0.88035, roc_auc: 0.91008
[[232 106]
 [ 15 326]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.82120, pr_auc: 0.88035, roc_auc: 0.91008
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.19it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.69it/s]
Epoch 10 : Training Loss: 0.01393, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00015, Time elapsed 0.25 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 16.05it/s]
val Evaluation: acc: 0.68141, pr_auc: 0.70373, roc_auc: 0.74778
[[194 144]
 [ 72 269]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.32it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.40it/s]
Epoch 11 : Training Loss: 0.00728, acc: 0.99434, pr_auc: 0.99973, roc_auc: 0.99975, LR: 0.00013, Time elapsed 0.24 mins
[[1638   13]
 [   5 1447]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.55it/s]
val Evaluation: acc: 0.77708, pr_auc: 0.86058, roc_auc: 0.86379
[[222 116]
 [ 35 306]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.09it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.75it/s]
Epoch 12 : Training Loss: 0.00724, acc: 0.99905, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00010, Time elapsed 0.25 mins
[[1649    2]
 [   1 1451]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.89it/s]
val Evaluation: acc: 0.71354, pr_auc: 0.77348, roc_auc: 0.79829
[[184 154]
 [ 40 301]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.49it/s]
Epoch 13 : Training Loss: 0.00162, acc: 0.99966, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00008, Time elapsed 0.24 mins
[[1651    0]
 [   1 1451]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 15.48it/s]
val Evaluation: acc: 0.69907, pr_auc: 0.75398, roc_auc: 0.78279
[[199 139]
 [ 65 276]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.11it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.29it/s]
Epoch 14 : Training Loss: 0.00123, acc: 0.99966, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00006, Time elapsed 0.25 mins
[[1651    0]
 [   1 1451]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 16.01it/s]
val Evaluation: acc: 0.67250, pr_auc: 0.79400, roc_auc: 0.77901
[[185 153]
 [ 69 272]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.27it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.61it/s]
Epoch 15 : Training Loss: 0.00228, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00004, Time elapsed 0.25 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.81it/s]
val Evaluation: acc: 0.65581, pr_auc: 0.69347, roc_auc: 0.74063
[[142 196]
 [ 37 304]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.17it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.60it/s]
Epoch 16 : Training Loss: 0.00102, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00003, Time elapsed 0.25 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 16.87it/s]
val Evaluation: acc: 0.68266, pr_auc: 0.75929, roc_auc: 0.78158
[[177 161]
 [ 54 287]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.20it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.78it/s]
Epoch 17 : Training Loss: 0.00038, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00002, Time elapsed 0.25 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.78it/s]
val Evaluation: acc: 0.65909, pr_auc: 0.74015, roc_auc: 0.76045
[[169 169]
 [ 62 279]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.22it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 16.28it/s]
Epoch 18 : Training Loss: 0.00041, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00001, Time elapsed 0.24 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.78it/s]
val Evaluation: acc: 0.67967, pr_auc: 0.75079, roc_auc: 0.77592
[[173 165]
 [ 52 289]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.16it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.47it/s]
Epoch 19 : Training Loss: 0.00037, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00000, Time elapsed 0.25 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 16.17it/s]
val Evaluation: acc: 0.69139, pr_auc: 0.76546, roc_auc: 0.78869
[[172 166]
 [ 43 298]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.33it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.07it/s]
Epoch 20 : Training Loss: 0.00043, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00000, Time elapsed 0.24 mins
[[1651    0]
 [   0 1452]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.60it/s]
val Evaluation: acc: 0.68256, pr_auc: 0.75289, roc_auc: 0.77844
[[170 168]
 [ 47 294]]
***************************Test************************
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00, 10.22it/s]
***************************Test results************************
Test Evaluation: acc: 0.57116, pr_auc: 0.53463, roc_auc: 0.65002
[[291 163]
 [184 185]]
model save in ./data/wjq/models_weights/Big/BigFaced/epoch20_acc_0.57116_pr_0.53463_roc_0.65002.pth
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
3090 705 810
4605
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=50, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=50, out_features=100, bias=True)
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Rearrange('b c s d -> b (c s d)')
    (1): Linear(in_features=19000, out_features=1000, bias=True)
    (2): ELU(alpha=1.0)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=100, bias=True)
    (5): ELU(alpha=1.0)
    (6): Dropout(p=0.1, inplace=False)
  )
  (final_classifier): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=1, bias=True)
    (4): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:13<00:00,  3.60it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 16.30it/s]
Epoch 1 : Training Loss: 0.52407, acc: 0.84858, pr_auc: 0.93154, roc_auc: 0.94130, LR: 0.00030, Time elapsed 0.28 mins
[[1460  159]
 [ 301 1170]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.11it/s]
val Evaluation: acc: 0.49565, pr_auc: 0.43035, roc_auc: 0.40069
[[242 112]
 [243 108]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.49565, pr_auc: 0.43035, roc_auc: 0.40069
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.24it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.37it/s]
Epoch 2 : Training Loss: 0.20709, acc: 0.96051, pr_auc: 0.99729, roc_auc: 0.99780, LR: 0.00029, Time elapsed 0.25 mins
[[1610    9]
 [ 108 1363]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.16it/s]
val Evaluation: acc: 0.32531, pr_auc: 0.36899, roc_auc: 0.29277
[[193 161]
 [314  37]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.21it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.92it/s]
Epoch 3 : Training Loss: 0.08975, acc: 0.98190, pr_auc: 0.99762, roc_auc: 0.99867, LR: 0.00028, Time elapsed 0.25 mins
[[1567   52]
 [   6 1465]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 17.51it/s]
val Evaluation: acc: 0.35375, pr_auc: 0.38045, roc_auc: 0.29634
[[ 79 275]
 [181 170]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.12it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.58it/s]
Epoch 4 : Training Loss: 0.05319, acc: 0.99707, pr_auc: 0.99910, roc_auc: 0.99949, LR: 0.00027, Time elapsed 0.25 mins
[[1615    4]
 [   5 1466]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.08it/s]
val Evaluation: acc: 0.47996, pr_auc: 0.52423, roc_auc: 0.42919
[[244 110]
 [256  95]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.47996, pr_auc: 0.52423, roc_auc: 0.42919
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 16.05it/s]
Epoch 5 : Training Loss: 0.02551, acc: 0.99691, pr_auc: 0.99965, roc_auc: 0.99975, LR: 0.00026, Time elapsed 0.24 mins
[[1609   10]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.09it/s]
val Evaluation: acc: 0.39465, pr_auc: 0.42400, roc_auc: 0.40803
[[113 241]
 [186 165]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.18it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.20it/s]
Epoch 6 : Training Loss: 0.01924, acc: 0.99907, pr_auc: 0.99997, roc_auc: 0.99997, LR: 0.00024, Time elapsed 0.25 mins
[[1616    3]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.92it/s]
val Evaluation: acc: 0.33755, pr_auc: 0.41108, roc_auc: 0.35003
[[123 231]
 [236 115]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.31it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.90it/s]
Epoch 7 : Training Loss: 0.01467, acc: 0.99503, pr_auc: 0.99996, roc_auc: 0.99996, LR: 0.00022, Time elapsed 0.24 mins
[[1604   15]
 [   1 1470]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.44it/s]
val Evaluation: acc: 0.35932, pr_auc: 0.38790, roc_auc: 0.34079
[[ 89 265]
 [187 164]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.10it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.03it/s]
Epoch 8 : Training Loss: 0.00782, acc: 0.99762, pr_auc: 0.99998, roc_auc: 0.99998, LR: 0.00020, Time elapsed 0.25 mins
[[1619    0]
 [   7 1464]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 17.71it/s]
val Evaluation: acc: 0.44465, pr_auc: 0.42142, roc_auc: 0.39810
[[219 135]
 [256  95]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.27it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.58it/s]
Epoch 9 : Training Loss: 0.01136, acc: 0.99938, pr_auc: 0.99999, roc_auc: 0.99999, LR: 0.00017, Time elapsed 0.25 mins
[[1617    2]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 14.84it/s]
val Evaluation: acc: 0.45966, pr_auc: 0.43302, roc_auc: 0.41063
[[156 198]
 [183 168]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.12it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.71it/s]
Epoch 10 : Training Loss: 0.00659, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00015, Time elapsed 0.25 mins
[[1619    0]
 [   0 1471]]
  0%|                                                                                                                   | 0/12 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 17.54it/s]
val Evaluation: acc: 0.60238, pr_auc: 0.55743, roc_auc: 0.65398
[[251 103]
 [177 174]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.60238, pr_auc: 0.55743, roc_auc: 0.65398
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.19it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.18it/s]
Epoch 11 : Training Loss: 0.00297, acc: 0.99966, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00013, Time elapsed 0.25 mins
[[1619    0]
 [   1 1470]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.28it/s]
val Evaluation: acc: 0.50251, pr_auc: 0.43974, roc_auc: 0.40303
[[264  90]
 [260  91]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.23it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.29it/s]
Epoch 12 : Training Loss: 0.00193, acc: 0.99907, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00010, Time elapsed 0.25 mins
[[1616    3]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 17.63it/s]
val Evaluation: acc: 0.48864, pr_auc: 0.44665, roc_auc: 0.45787
[[233 121]
 [239 112]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:10<00:00,  4.50it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.09it/s]
Epoch 13 : Training Loss: 0.00463, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00008, Time elapsed 0.24 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.02it/s]
val Evaluation: acc: 0.41999, pr_auc: 0.43261, roc_auc: 0.39540
[[138 216]
 [193 158]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.21it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 16.14it/s]
Epoch 14 : Training Loss: 0.00082, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00006, Time elapsed 0.24 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.11it/s]
val Evaluation: acc: 0.42232, pr_auc: 0.42327, roc_auc: 0.41225
[[181 173]
 [234 117]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.32it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.21it/s]
Epoch 15 : Training Loss: 0.00021, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00004, Time elapsed 0.25 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.06it/s]
val Evaluation: acc: 0.42107, pr_auc: 0.41440, roc_auc: 0.40238
[[166 188]
 [220 131]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.21it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 16.14it/s]
Epoch 16 : Training Loss: 0.00013, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00003, Time elapsed 0.24 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.08it/s]
val Evaluation: acc: 0.42657, pr_auc: 0.41706, roc_auc: 0.40778
[[183 171]
 [233 118]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.14it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.81it/s]
Epoch 17 : Training Loss: 0.00020, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00002, Time elapsed 0.25 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.08it/s]
val Evaluation: acc: 0.41253, pr_auc: 0.41293, roc_auc: 0.40029
[[166 188]
 [226 125]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.31it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 15.07it/s]
Epoch 18 : Training Loss: 0.00005, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00001, Time elapsed 0.24 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 15.16it/s]
val Evaluation: acc: 0.42523, pr_auc: 0.41720, roc_auc: 0.40680
[[176 178]
 [227 124]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:11<00:00,  4.28it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:03<00:00, 14.32it/s]
Epoch 19 : Training Loss: 0.00006, acc: 1.00000, pr_auc: 1.00000, roc_auc: 1.00000, LR: 0.00000, Time elapsed 0.25 mins
[[1619    0]
 [   0 1471]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.00it/s]
val Evaluation: acc: 0.42951, pr_auc: 0.41725, roc_auc: 0.40709
[[175 179]
 [223 128]]
  0%|                                                                                                                   | 0/49 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 76%|████████████████████████████████████████████████████████████████████████████████                          | 37/49 [00:08<00:02,  4.39it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 110, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 86, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer_kfold.py", line 81, in train_for_binaryclass
    for x, y in tqdm(self.data_loader['train'], mininterval=10):
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 790, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/datasets/pearl_kfold_dataset.py", line 27, in __getitem__
    pair = pickle.loads(txn.get(key.encode()))
                        ^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x75204bddc040>
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
