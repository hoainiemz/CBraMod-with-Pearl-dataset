502 117 133
752
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=200, bias=True)
    (4): ELU(alpha=1.0)
  )
  (arranger): Rearrange('b c s d -> b (c s) d')
  (attention): ParamAttention(
    (Wq): Linear(in_features=200, out_features=200, bias=False)
    (Wk): Linear(in_features=200, out_features=200, bias=False)
    (Wv): Linear(in_features=200, out_features=200, bias=False)
    (drop): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=200, out_features=1, bias=True)
    (1): Rearrange('b 1 -> (b 1)')
  )
)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.01s/it]
Epoch 1 : Training Loss: 0.69423, LR: 0.00030, Time elapsed 0.14 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.31it/s]
val Evaluation: acc: 0.50000, pr_auc: 0.36118, roc_auc: 0.45105
[[78  0]
 [55  0]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50000, pr_auc: 0.36118, roc_auc: 0.45105
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.24it/s]
Epoch 2 : Training Loss: 0.69374, LR: 0.00029, Time elapsed 0.11 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.55it/s]
val Evaluation: acc: 0.50000, pr_auc: 0.39916, roc_auc: 0.44545
[[ 0 78]
 [ 0 55]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.09it/s]
Epoch 3 : Training Loss: 0.69452, LR: 0.00028, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.34it/s]
val Evaluation: acc: 0.50000, pr_auc: 0.45254, roc_auc: 0.50559
[[78  0]
 [55  0]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50000, pr_auc: 0.45254, roc_auc: 0.50559
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
Epoch 4 : Training Loss: 0.63406, LR: 0.00027, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.41it/s]
val Evaluation: acc: 0.58636, pr_auc: 0.35467, roc_auc: 0.41772
[[39 39]
 [18 37]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 5 : Training Loss: 0.37842, LR: 0.00026, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.45it/s]
val Evaluation: acc: 0.58636, pr_auc: 0.58779, roc_auc: 0.56247
[[39 39]
 [18 37]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.58636, pr_auc: 0.58779, roc_auc: 0.56247
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 6 : Training Loss: 0.24999, LR: 0.00024, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.41it/s]
val Evaluation: acc: 0.36562, pr_auc: 0.57424, roc_auc: 0.50653
[[23 55]
 [31 24]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 7 : Training Loss: 0.15698, LR: 0.00022, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.43it/s]
val Evaluation: acc: 0.31107, pr_auc: 0.44008, roc_auc: 0.41119
[[23 55]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 8 : Training Loss: 0.03776, LR: 0.00020, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.45it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.40270, roc_auc: 0.41608
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 9 : Training Loss: 0.03159, LR: 0.00017, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.46it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.40609, roc_auc: 0.42657
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 10 : Training Loss: 0.03886, LR: 0.00015, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.47it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.54429, roc_auc: 0.46667
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 11 : Training Loss: 0.00942, LR: 0.00013, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.43it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.55660, roc_auc: 0.46993
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 12 : Training Loss: 0.00567, LR: 0.00010, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.45it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.52916, roc_auc: 0.46632
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 13 : Training Loss: 0.00783, LR: 0.00008, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.39it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.53118, roc_auc: 0.46853
[[20 58]
 [37 18]]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.10it/s]
Epoch 14 : Training Loss: 0.01250, LR: 0.00006, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.45it/s]
val Evaluation: acc: 0.29184, pr_auc: 0.56767, roc_auc: 0.49604
[[20 58]
 [37 18]]
 75%|█████████████████████████████████████████████████████████████████████████████████                           | 6/8 [00:05<00:01,  1.01it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 111, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 86, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer_kfold.py", line 89, in train_for_binaryclass
    loss.backward()
  File "/mnt/disk1/aiotlab/envs/cbramod/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/mnt/disk1/aiotlab/envs/cbramod/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/mnt/disk1/aiotlab/envs/cbramod/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
