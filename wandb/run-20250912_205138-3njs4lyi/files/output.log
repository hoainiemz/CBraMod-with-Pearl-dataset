Namespace(seed=3407, cuda=0, epochs=50, batch_size=64, lr=0.0001, weight_decay=0.05, optimizer='AdamW', clip_value=1, dropout=0.1, classifier='all_patch_reps', downstream_dataset='PEARL', datasets_dir='/mnt/disk1/aiotlab/namth/EEGFoundationModel/datasets/pearl', num_of_classes=2, model_dir='./data/wjq/models_weights/Big/BigFaced', num_workers=16, label_smoothing=0.1, multi_lr=False, frozen=False, use_pretrained_weights=True, foundation_dir='pretrained_weights/pretrained_weights.pth')
The downstream dataset is PEARL
3255 476 874
4605
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=50, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=50, out_features=100, bias=True)
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=100, bias=True)
  )
  (classifier): Sequential(
    (0): Rearrange('b c s d -> b (c s d)')
    (1): Linear(in_features=19000, out_features=1000, bias=True)
    (2): ELU(alpha=1.0)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=100, bias=True)
    (5): ELU(alpha=1.0)
    (6): Dropout(p=0.1, inplace=False)
  )
  (final_classifier): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=1, bias=True)
    (4): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:06<00:00,  8.23it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 42.42it/s]
Epoch 1 : Training Loss: 0.61842, acc: 0.50420, pr_auc: 0.49987, roc_auc: 0.54489, LR: 0.00010, Time elapsed 0.11 mins
[[100 138]
 [ 98 140]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 45.32it/s]
Val Evaluation: acc: 0.56873, pr_auc: 0.76993, roc_auc: 0.67213
[[243 225]
 [155 251]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50420, pr_auc: 0.49987, roc_auc: 0.54489
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.11it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 46.54it/s]
Epoch 2 : Training Loss: 0.41869, acc: 0.50420, pr_auc: 0.54158, roc_auc: 0.62367, LR: 0.00010, Time elapsed 0.08 mins
[[190  48]
 [188  50]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 46.50it/s]
Val Evaluation: acc: 0.73474, pr_auc: 0.83540, roc_auc: 0.84125
[[403  65]
 [159 247]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50420, pr_auc: 0.54158, roc_auc: 0.62367
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.30it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.15it/s]
Epoch 3 : Training Loss: 0.26178, acc: 0.51050, pr_auc: 0.52065, roc_auc: 0.57046, LR: 0.00010, Time elapsed 0.08 mins
[[138 100]
 [133 105]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 47.72it/s]
Val Evaluation: acc: 0.77146, pr_auc: 0.88759, roc_auc: 0.88823
[[344 124]
 [ 78 328]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.61it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.74it/s]
Epoch 4 : Training Loss: 0.20878, acc: 0.46218, pr_auc: 0.47331, roc_auc: 0.51287, LR: 0.00010, Time elapsed 0.08 mins
[[143  95]
 [161  77]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 46.75it/s]
Val Evaluation: acc: 0.75628, pr_auc: 0.82261, roc_auc: 0.84117
[[354 114]
 [ 99 307]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.61it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.64it/s]
Epoch 5 : Training Loss: 0.14102, acc: 0.44748, pr_auc: 0.45053, roc_auc: 0.41844, LR: 0.00010, Time elapsed 0.08 mins
[[148  90]
 [173  65]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 47.87it/s]
Val Evaluation: acc: 0.74814, pr_auc: 0.80860, roc_auc: 0.81264
[[419  49]
 [162 244]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.98it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.90it/s]
Epoch 6 : Training Loss: 0.09380, acc: 0.48319, pr_auc: 0.50088, roc_auc: 0.51926, LR: 0.00010, Time elapsed 0.07 mins
[[154  84]
 [162  76]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 48.59it/s]
Val Evaluation: acc: 0.74897, pr_auc: 0.82770, roc_auc: 0.83015
[[429  39]
 [170 236]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.50it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.75it/s]
Epoch 7 : Training Loss: 0.06219, acc: 0.48529, pr_auc: 0.54620, roc_auc: 0.49426, LR: 0.00010, Time elapsed 0.08 mins
[[147  91]
 [154  84]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 47.43it/s]
Val Evaluation: acc: 0.74289, pr_auc: 0.81520, roc_auc: 0.79593
[[421  47]
 [168 238]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.93it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.24it/s]
Epoch 8 : Training Loss: 0.03994, acc: 0.49580, pr_auc: 0.48960, roc_auc: 0.42705, LR: 0.00009, Time elapsed 0.07 mins
[[146  92]
 [148  90]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 47.74it/s]
Val Evaluation: acc: 0.75908, pr_auc: 0.86531, roc_auc: 0.87066
[[435  33]
 [167 239]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:04<00:00, 11.93it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.92it/s]
Epoch 9 : Training Loss: 0.04012, acc: 0.51471, pr_auc: 0.55914, roc_auc: 0.55780, LR: 0.00009, Time elapsed 0.07 mins
[[175  63]
 [168  70]]
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████▍       | 13/14 [00:00<00:00, 45.47it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 170, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 156, in main
    t.train_for_binaryclass()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py", line 213, in train_for_binaryclass
    test_acc, test_pr_auc, test_roc_auc, test_cm = self.test_eval.get_metrics_for_binaryclass(self.model)
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_evaluator.py", line 47, in get_metrics_for_binaryclass
    pred = model(x)
           ^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_pearl.py", line 60, in forward
    f1 = fork(self.eeg_backbone, x[0])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/jit/_async.py", line 99, in fork
    return torch._C.fork(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_pearl.py", line 53, in eeg_backbone
    return self.classifier(self.backbone(x))
                           ^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/cbramod.py", line 29, in forward
    feats = self.encoder(patch_emb)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 29, in forward
    output = mod(output, src_mask=mask)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 90, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 107, in _sa_block
    xt = self.self_attn_t(xt, xt, xt,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 1320, in forward
    return torch._native_multi_head_attention(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
