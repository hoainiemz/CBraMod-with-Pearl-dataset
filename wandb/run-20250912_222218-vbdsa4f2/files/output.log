Namespace(seed=3407, cuda=0, epochs=50, batch_size=64, lr=0.0003, weight_decay=0.05, optimizer='AdamW', clip_value=1, dropout=0.1, classifier='all_patch_reps', downstream_dataset='PEARL', datasets_dir='/mnt/disk1/aiotlab/namth/EEGFoundationModel/datasets/pearl', num_of_classes=2, model_dir='./data/wjq/models_weights/Big/BigFaced', num_workers=16, label_smoothing=0.1, multi_lr=False, frozen=False, use_pretrained_weights=True, foundation_dir='pretrained_weights/pretrained_weights.pth')
The downstream dataset is PEARL
3339 460 806
4605
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=50, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=50, out_features=100, bias=True)
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=100, out_features=100, bias=True)
  )
  (classifier): Sequential(
    (0): Rearrange('b c s d -> b (c s d)')
    (1): Linear(in_features=19000, out_features=1000, bias=True)
    (2): ELU(alpha=1.0)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=100, bias=True)
    (5): ELU(alpha=1.0)
    (6): Dropout(p=0.1, inplace=False)
  )
  (final_classifier): Sequential(
    (0): Linear(in_features=100, out_features=100, bias=True)
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=1, bias=True)
    (4): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:06<00:00,  8.45it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 44.71it/s]
Epoch 1 : Training Loss: 0.53410, acc: 0.70656, pr_auc: 0.87013, roc_auc: 0.85742, LR: 0.00030, Time elapsed 0.11 mins
[[161  66]
 [ 69 164]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 46.22it/s]
Val Evaluation: acc: 0.50018, pr_auc: 0.51734, roc_auc: 0.45925
[[319 145]
 [235 107]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.70656, pr_auc: 0.87013, roc_auc: 0.85742
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 12.14it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.50it/s]
Epoch 2 : Training Loss: 0.29115, acc: 0.72186, pr_auc: 0.86149, roc_auc: 0.85965, LR: 0.00030, Time elapsed 0.08 mins
[[166  61]
 [ 67 166]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.59it/s]
Val Evaluation: acc: 0.61174, pr_auc: 0.55973, roc_auc: 0.51240
[[276 188]
 [127 215]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.72186, pr_auc: 0.86149, roc_auc: 0.85965
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.75it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.93it/s]
Epoch 3 : Training Loss: 0.18398, acc: 0.74315, pr_auc: 0.85279, roc_auc: 0.85325, LR: 0.00030, Time elapsed 0.08 mins
[[163  64]
 [ 54 179]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.39it/s]
Val Evaluation: acc: 0.61332, pr_auc: 0.62898, roc_auc: 0.58122
[[386  78]
 [207 135]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.94it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.76it/s]
Epoch 4 : Training Loss: 0.05913, acc: 0.66223, pr_auc: 0.86370, roc_auc: 0.85841, LR: 0.00030, Time elapsed 0.08 mins
[[174  53]
 [103 130]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.01it/s]
Val Evaluation: acc: 0.65358, pr_auc: 0.70377, roc_auc: 0.66242
[[441  23]
 [220 122]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.92it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.30it/s]
Epoch 5 : Training Loss: 0.02113, acc: 0.66906, pr_auc: 0.82345, roc_auc: 0.83065, LR: 0.00029, Time elapsed 0.08 mins
[[181  46]
 [107 126]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 47.21it/s]
Val Evaluation: acc: 0.76545, pr_auc: 0.67341, roc_auc: 0.67082
[[420  44]
 [128 214]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.54it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.31it/s]
Epoch 6 : Training Loss: 0.00476, acc: 0.65376, pr_auc: 0.69521, roc_auc: 0.73186, LR: 0.00029, Time elapsed 0.08 mins
[[176  51]
 [109 124]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 47.62it/s]
Val Evaluation: acc: 0.73489, pr_auc: 0.65461, roc_auc: 0.71946
[[393  71]
 [129 213]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 10.91it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.15it/s]
Epoch 7 : Training Loss: 0.01236, acc: 0.75665, pr_auc: 0.88524, roc_auc: 0.88026, LR: 0.00029, Time elapsed 0.08 mins
[[174  53]
 [ 59 174]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.08it/s]
Val Evaluation: acc: 0.71934, pr_auc: 0.66378, roc_auc: 0.71534
[[365  99]
 [119 223]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.75665, pr_auc: 0.88524, roc_auc: 0.88026
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 10.84it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.23it/s]
Epoch 8 : Training Loss: 0.00131, acc: 0.76738, pr_auc: 0.87806, roc_auc: 0.88015, LR: 0.00028, Time elapsed 0.08 mins
[[174  53]
 [ 54 179]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 46.76it/s]
Val Evaluation: acc: 0.73120, pr_auc: 0.59360, roc_auc: 0.65658
[[395  69]
 [133 209]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.23it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.97it/s]
Epoch 9 : Training Loss: 0.00130, acc: 0.84667, pr_auc: 0.84427, roc_auc: 0.85485, LR: 0.00028, Time elapsed 0.08 mins
[[172  55]
 [ 15 218]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.16it/s]
Val Evaluation: acc: 0.60370, pr_auc: 0.54961, roc_auc: 0.63774
[[392  72]
 [218 124]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.39it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.92it/s]
Epoch 10 : Training Loss: 0.00279, acc: 0.77409, pr_auc: 0.83359, roc_auc: 0.83426, LR: 0.00027, Time elapsed 0.08 mins
[[141  86]
 [ 17 216]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 47.73it/s]
Val Evaluation: acc: 0.54521, pr_auc: 0.52883, roc_auc: 0.58153
[[354 110]
 [230 112]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.30it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 46.70it/s]
Epoch 11 : Training Loss: 0.00551, acc: 0.77342, pr_auc: 0.82676, roc_auc: 0.84641, LR: 0.00027, Time elapsed 0.08 mins
[[167  60]
 [ 44 189]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 46.05it/s]
Val Evaluation: acc: 0.64009, pr_auc: 0.63340, roc_auc: 0.66151
[[381  83]
 [185 157]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.36it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.46it/s]
Epoch 12 : Training Loss: 0.00333, acc: 0.72677, pr_auc: 0.83840, roc_auc: 0.82892, LR: 0.00026, Time elapsed 0.08 mins
[[139  88]
 [ 37 196]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 47.79it/s]
Val Evaluation: acc: 0.55237, pr_auc: 0.53460, roc_auc: 0.61367
[[362 102]
 [231 111]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.42it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.53it/s]
Epoch 13 : Training Loss: 0.00019, acc: 0.70774, pr_auc: 0.85659, roc_auc: 0.84150, LR: 0.00025, Time elapsed 0.08 mins
[[144  83]
 [ 51 182]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 47.60it/s]
Val Evaluation: acc: 0.60331, pr_auc: 0.56371, roc_auc: 0.67884
[[374  90]
 [205 137]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:04<00:00, 11.46it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.82it/s]
Epoch 14 : Training Loss: 0.00259, acc: 0.76731, pr_auc: 0.85646, roc_auc: 0.84292, LR: 0.00025, Time elapsed 0.08 mins
[[135  92]
 [ 14 219]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 48.03it/s]
Val Evaluation: acc: 0.61477, pr_auc: 0.58057, roc_auc: 0.69391
[[367  97]
 [192 150]]
 74%|██████████████████████████████████████████████████████████████████████████████                            | 39/53 [00:03<00:01, 11.50it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 170, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_main.py", line 156, in main
    t.train_for_binaryclass()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer.py", line 175, in train_for_binaryclass
    pred = self.model(x)
           ^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_pearl.py", line 64, in forward
    f1 = fork(self.eeg_backbone, x[0])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/jit/_async.py", line 99, in fork
    return torch._C.fork(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/model_for_pearl.py", line 57, in eeg_backbone
    return self.classifier(self.backbone(x))
                           ^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/cbramod.py", line 29, in forward
    feats = self.encoder(patch_emb)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 29, in forward
    output = mod(output, src_mask=mask)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 90, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/models/criss_cross_transformer.py", line 102, in _sa_block
    xs = self.self_attn_s(xs, xs, xs,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/modules/activation.py", line 1380, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/envs/hoainiem/lib/python3.12/site-packages/torch/nn/functional.py", line 6484, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
