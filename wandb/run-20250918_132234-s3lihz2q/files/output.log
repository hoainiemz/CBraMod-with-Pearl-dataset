490 127 135
752
Model(
  (backbone): CBraMod(
    (patch_embedding): PatchEmbedding(
      (positional_encoding): Sequential(
        (0): Conv2d(200, 200, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3), groups=200)
      )
      (proj_in): Sequential(
        (0): Conv2d(1, 25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24))
        (1): GroupNorm(5, 25, eps=1e-05, affine=True)
        (2): GELU(approximate='none')
        (3): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (4): GroupNorm(5, 25, eps=1e-05, affine=True)
        (5): GELU(approximate='none')
        (6): Conv2d(25, 25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
        (7): GroupNorm(5, 25, eps=1e-05, affine=True)
        (8): GELU(approximate='none')
      )
      (spectral_proj): Sequential(
        (0): Linear(in_features=101, out_features=200, bias=True)
        (1): Dropout(p=0.1, inplace=False)
      )
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayer(
          (self_attn_s): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (self_attn_t): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)
          )
          (linear1): Linear(in_features=200, out_features=800, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=800, out_features=200, bias=True)
          (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (proj_out): Identity()
  )
  (meta_backbone): Sequential(
    (0): Linear(in_features=28, out_features=100, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=100, out_features=200, bias=True)
    (4): ReLU()
  )
  (arranger): Rearrange('b c s d -> b (c s) d')
  (attention): ParamAttention(
    (Wq): Linear(in_features=200, out_features=200, bias=False)
    (Wk): Linear(in_features=200, out_features=200, bias=False)
    (Wv): Linear(in_features=200, out_features=200, bias=False)
    (drop): Dropout(p=0.1, inplace=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=200, out_features=1, bias=True)
    (1): Rearrange('b 1 -> (b 1)')
  )
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.02it/s]
Epoch 1 : Training Loss: 0.71680, LR: 0.00050, Time elapsed 0.13 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.51it/s]
val Evaluation: acc: 0.50000, pr_auc: 0.60175, roc_auc: 0.48507
[[60  0]
 [67  0]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50000, pr_auc: 0.60175, roc_auc: 0.48507
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.14it/s]
Epoch 2 : Training Loss: 0.69326, LR: 0.00050, Time elapsed 0.12 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.69it/s]
val Evaluation: acc: 0.50000, pr_auc: 0.66083, roc_auc: 0.49975
[[60  0]
 [67  0]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.50000, pr_auc: 0.66083, roc_auc: 0.49975
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  3.07it/s]
Epoch 3 : Training Loss: 0.61531, LR: 0.00050, Time elapsed 0.09 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.30it/s]
val Evaluation: acc: 0.66667, pr_auc: 0.97977, roc_auc: 0.97214
[[20 40]
 [ 0 67]]
roc_auc increasing....saving weights !!
Val Evaluation: acc: 0.66667, pr_auc: 0.97977, roc_auc: 0.97214
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:06<00:00,  2.54it/s]
Epoch 4 : Training Loss: 0.23390, LR: 0.00049, Time elapsed 0.10 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.85it/s]
val Evaluation: acc: 0.64179, pr_auc: 0.79928, roc_auc: 0.79950
[[60  0]
 [48 19]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.13it/s]
Epoch 5 : Training Loss: 0.11117, LR: 0.00049, Time elapsed 0.13 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.24it/s]
val Evaluation: acc: 0.70734, pr_auc: 0.74745, roc_auc: 0.75460
[[41 19]
 [18 49]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.08it/s]
Epoch 6 : Training Loss: 0.01459, LR: 0.00048, Time elapsed 0.13 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.52it/s]
val Evaluation: acc: 0.69988, pr_auc: 0.57357, roc_auc: 0.68694
[[41 19]
 [19 48]]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.92it/s]
Epoch 7 : Training Loss: 0.00003, LR: 0.00048, Time elapsed 0.09 mins
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 13.83it/s]
val Evaluation: acc: 0.69988, pr_auc: 0.57204, roc_auc: 0.68458
[[41 19]
 [19 48]]
 56%|████████████████████████████████████████████████████████████▏                                              | 9/16 [00:02<00:01,  3.79it/s]
Traceback (most recent call last):
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 112, in <module>
    main()
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_kfold_pearl.py", line 86, in main
    acc_, pr_auc_, roc_auc_ = t.train_for_binaryclass()
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/disk1/aiotlab/namth/EEGFoundationModel/CBraMod/finetune_trainer_kfold.py", line 90, in train_for_binaryclass
    losses.append(loss.data.cpu().numpy())
                  ^^^^^^^^^^^^^^^
KeyboardInterrupt
